?posterior_summary
??posterior_summary
??posterior_summary
library(brms)
summary(fit_default)
summary(fit2)
# Specify the model using incorrect priors
model_crazy <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(1, 0.2)")*F2 + prior("normal(1, 0.2)")*F1
F4 ~ prior("normal(2, 0.2)")*F2 + prior("normal(1, 0.2)")*F3
'
# Re-fitting
fit_crazy <- bsem(model_crazy, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Note: Default prior for regression parameters is normal(0,10)
summary(fit_crazy)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(rlang)
install.packages(c("admisc", "arm", "askpass", "backports", "BH", "brew", "brio", "broom", "bslib", "cachem", "Cairo", "callr", "car", "checkmate", "cli", "coda", "colorspace", "corrplot", "cowplot", "cpp11", "crayon", "credentials", "curl", "cyclocomp", "data.table", "desc", "digest", "downlit", "dplyr", "energy", "evaluate", "expm", "fable", "fabletools", "fansi", "farver", "fastmap", "fdrtool", "feasts", "fontawesome", "fpp3", "fs", "gert", "ggrepel", "ggsci", "ggthemes", "gh", "glue", "GPArotation", "gtable", "gtools", "haven", "highr", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "httpgd", "httpuv", "httr", "httr2", "igraph", "jsonlite", "knitr", "kutils", "labeling", "languageserver", "later", "lifecycle", "lintr", "lisrelToR", "lme4", "loo", "lubridate", "MatrixModels", "minqa", "mirt", "msm", "munsell", "mvtnorm", "nloptr", "OpenMx", "openssl", "openxlsx", "pbapply", "pbkrtest", "pkgbuild", "pkgdown", "pkgload", "plyr", "posterior", "prettyunits", "processx", "profvis", "progress", "progressr", "promises", "ps", "psych", "purrr", "qgraph", "quantreg", "QuickJSR", "qwraps2", "R.oo", "R.utils", "ragg", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "readr", "readxl", "rematch", "remotes", "rJava", "rlang", "rmarkdown", "roxygen2", "rpf", "rprojroot", "rstudioapi", "RUnit", "sass", "shiny", "slider", "SparseM", "StanHeaders", "stringi", "stringr", "styler", "sys", "systemfonts", "testthat", "textshaping", "tibble", "tidyr", "timechange", "tinytex", "tsibble", "tzdb", "usethis", "utf8", "vctrs", "vegan", "viridis", "viridisLite", "vroom", "waldo", "warp", "withr", "xfun", "XLConnect", "XML", "xml2", "xopen", "yaml", "zip"))
install.packages("rlang")
install.packages("rlang")
remove.packages(rlang)
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
knitr::include_graphics('GeneralModel.png')
load('SimData.Rdata')
library(blavaan)
model <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(0.3, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F1
F4 ~ prior("normal(0, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F3
'
fit <- bsem(model, data = SimData, n.chains = 4, burnin = 100, sample = 500)
# Trace plot to check convergence of the regression parameters
plot(fit, pars = 17:20, plot.type = "trace")
# Rhat to check convergence of all parameters
blavInspect(fit, "rhat")
# Re-fitting
fit2 <- bsem(model, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Trace plot to check convergence of the regression parameters
plot(fit2, pars = 17:20, plot.type = "trace")
# Rhat to check convergence of all parameters
blavInspect(fit2, "rhat")
# Trace plot to check convergence of the regression parameters
plot(fit2, pars = 17:20, plot.type = "hist")
plot(fit2, pars = 17:20, plot.type = "acf")
# Specify the model
model_default <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ F2 + F1
F4 ~ F2 + F3
'
# Re-fitting
fit_default <- bsem(model_default, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Note: Default prior for regression parameters is normal(0,10)
# Specify the model using incorrect priors
model_crazy <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(1, 0.2)")*F2 + prior("normal(1, 0.2)")*F1
F4 ~ prior("normal(2, 0.2)")*F2 + prior("normal(1, 0.2)")*F3
'
# Re-fitting
fit_crazy <- bsem(model_crazy, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Extract regression parameters of the three fitted models
betas_fit2 <- blavInspect(fit2, )
blavInspect(fit2, "postmean")
knitr::opts_chunk$set(echo = TRUE)
blavInspect(blavobject = fit2, what = "postmean")[17:20]
# Extract regression parameters of the three fitted models
betas_fit2        <- blavInspect(blavobject = fit2,        what = "postmean")[17:20]
betas_fit_default <- blavInspect(blavobject = fit_default, what = "postmean")[17:20]
betas_fit_crazy   <- blavInspect(blavobject = fit_crazy,   what = "postmean")[17:20]
betas_fit2
betas_fit_default
betas_fit_crazy
101/100
1/100
-15/10
round(100*(betas_fit_default - betas_fit2/betas_fit2))
round(100*(betas_fit_crazy   - betas_fit2/betas_fit2))
betas_fit_default - betas_fit2/betas_fit2
round(100*(betas_fit_default - betas_fit2/betas_fit2), 4)
round(100*(betas_fit_crazy   - betas_fit2/betas_fit2), 4)
betas_fit_default
betas_fit_default - betas_fit2/betas_fit2
betas_fit_default - betas_fit2
round(100*((betas_fit_default - betas_fit2)/betas_fit2), 4)
round(100*((betas_fit_crazy   - betas_fit2)/betas_fit2), 4)
(betas_fit_default - betas_fit2)/betas_fit2
100*((betas_fit_default - betas_fit2)/betas_fit2)
betas_fit2
betas_fit_default
round((betas_fit_default - betas_fit2), 4)
round(abs(betas_fit_default - betas_fit2), 4)
round(abs(betas_fit_crazy   - betas_fit2), 4)
round(100*((betas_fit_crazy   - betas_fit2)/betas_fit2), 4)
# Checking absolute bias
round(abs(betas_fit_default - betas_fit2), 4)
round(abs(betas_fit_crazy   - betas_fit2), 4)
ppmc(object = fit2)
post_pc <- ppmc(object = fit2)
post_pc <- ppmc(object = fit2, , fit.measures = c("srmr","chisq","rmsea","cfi"))
post_pc <- ppmc(object = fit2, fit.measures = c("srmr","chisq","rmsea","cfi"))
post_pc
warnings()[1:5]
fit2
summary(fit2)
summary(post_pc)
hist(fit2)
hist(post_pc)
plot(post_pc)
library(blavaan)
model <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(0.3, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F1
F4 ~ prior("normal(0, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F3
'
# Fit a model that only takes the prior distributions into account
prior_pred_check <- bsem(model, data = SimData, n.chains = 4, burnin = 100, sample = 500, prisamp = T)
# Check densities of the regression parameters using the prior distributions
plot(prior_pred_check, pars=17:20, plot.type = "dens")
posterior_pred_check <- ppmc(fit2, thin = 10, fit.measures = c("rmsea","cfi"))
summary(posterior_pred_check)
posterior_pred_check <- ppmc(fit2, thin = 10, fit.measures = c("rmsea"))
posterior_pred_check <- ppmc(fit2, discFUN = discFUN)
# Check the posterior predicted distributions of the observed variables
# Define function to be inserted in ppmc()
discFUN <- list(ov_pred = function(fit) {
preds <- lavPredict(fit, type="ov")
})
posterior_pred_check <- ppmc(fit2, discFUN = discFUN)
library(lavaan)
library(blavaan)
model <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(0.3, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F1
F4 ~ prior("normal(0, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F3
'
# Check the posterior predicted distributions of the observed variables
# Define function to be inserted in ppmc()
discFUN <- list(ov_pred = function(fit) {
preds <- lavPredict(fit, type="ov")
})
posterior_pred_check <- ppmc(fit2, discFUN = discFUN)
summary(posterior_pred_check)
# Check the
posterior_pred_check <- ppmc(fit2, discFUN = discFUN, thin = 10)
summary(posterior_pred_check)
# Check the distribution of the observed variables based on the posteriors
posterior_pred_check <- ppmc(fit2, discFUN = discFUN, thin = 5)
# Extract the means of the posterior predictive values
post_means <- t(sapply(posterior_pred_check@obsDist$ov_pred, colMeans))
View(post_means)
# Plot the real data against the posterior draws
plot(density(post_means[,"x1"]))
abline(v = mean(SimData[,"x1"]), col = "red")
plot(density(post_means[,"x1"]))
abline(v = mean(SimData[,"x1"]), col = "red")
# Check the posterior predicted distributions of the observed variables
psamps <- do.call("rbind", blavInspect(fit2, 'mcmc'))
lvsamps <- do.call("rbind", blavInspect(fit2, 'lvs'))
# Re-fitting
fit2 <- bsem(model, data = SimData, n.chains = 4, burnin = 200, sample = 1000, save.lvs=TRUE)
lvsamps <- do.call("rbind", blavInspect(fit2, 'lvs'))
psamps
# Use 50 random posterior draws
rand_samp <- sample(1:nrow(psamps), 50)
par(mfrow=c(3,3))
rand_samp
cmns[[1]][[1]][,1]
# Check the distribution of the observed variables based on the posteriors
posterior_pred_check <- lapply(seq(nrow(psamps)), function(i){
lavmodel <- blavaan:::fill_params(psamps[i,], fit@Model, fit@ParTable)
eta <- blavaan:::fill_eta(lvsamps[i,], fit@Model, fit@ParTable,
fit@SampleStats, fit@Data)
lavaan:::computeYHAT(lavmodel, lavmodel@GLIST, fit@SampleStats, ETA = eta)
})
posterior_pred_check[[1]][[1]][,1]
posterior_pred_check[[1]][[1]]
View(SimData)
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]) )
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]) )
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), type = "dashed")
}
par(mfrow=c(3,3))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed")
}
par(mfrow=c(1,1))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed")
}
library(scales)
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("scales")
library(scales)
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", alpha = 0.5)
}
par(mfrow=c(1,1))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", alpha = 0.3)
}
?alpha
par(mfrow=c(1,1))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.2))
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.2))
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.2))
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
# Plot the real data against the posterior draws for all variables
var_names <- colnames(SimData)
var_names <- colnames(SimData)
par(mfrow=c(2,2))
for(var in 1:20){
plot(density(SimData[,var]), col="red", lwd=4, ylim=c(0,.6), main= paste("Distributions for variable", var_names[var]))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,var]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
}
knitr::opts_chunk$set(echo = TRUE)
# Load necessary packages
library(lavaan)
library(blavaan)
library(scales)
knitr::include_graphics('GeneralModel.png')
load('SimData.Rdata')
model <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(0.3, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F1
F4 ~ prior("normal(0, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F3
'
fit <- bsem(model, data = SimData, n.chains = 4, burnin = 100, sample = 500)
# Trace plot to check convergence of the regression parameters
plot(fit, pars = 17:20, plot.type = "trace")
# Rhat to check convergence of all parameters
blavInspect(fit, "rhat")
# Re-fitting
fit2 <- bsem(model, data = SimData, n.chains = 4, burnin = 200, sample = 1000, save.lvs=TRUE) # Save factor scores for later
# Trace plot to check convergence of the regression parameters
plot(fit2, pars = 17:20, plot.type = "trace")
# Rhat to check convergence of all parameters
blavInspect(fit2, "rhat")
# Trace plot to check convergence of the regression parameters
plot(fit2, pars = 17:20, plot.type = "hist")
plot(fit2, pars = 17:20, plot.type = "acf")
# Specify the model
model_default <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ F2 + F1
F4 ~ F2 + F3
'
# Re-fitting
fit_default <- bsem(model_default, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Note: Default prior for regression parameters is normal(0,10)
# Specify the model using incorrect priors
model_crazy <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(1, 0.2)")*F2 + prior("normal(1, 0.2)")*F1
F4 ~ prior("normal(2, 0.2)")*F2 + prior("normal(1, 0.2)")*F3
'
# Re-fitting
fit_crazy <- bsem(model_crazy, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Extract regression parameters of the three fitted models
betas_fit2        <- blavInspect(blavobject = fit2,        what = "postmean")[17:20] # Original fit
betas_fit_default <- blavInspect(blavobject = fit_default, what = "postmean")[17:20] # Default priors
betas_fit_crazy   <- blavInspect(blavobject = fit_crazy,   what = "postmean")[17:20] # Crazy priors
# Checking absolute bias
round(abs(betas_fit_default - betas_fit2), 4)
round(abs(betas_fit_crazy   - betas_fit2), 4)
# Fit a model that only takes the prior distributions into account
prior_pred_check <- bsem(model, data = SimData, n.chains = 4, burnin = 200, sample = 1000, prisamp = T)
# Check densities of the regression parameters using the prior distributions
plot(prior_pred_check, pars=17:20, plot.type = "dens")
# NOTE: In blavaan, the posterior predictive checks seem to be more oriented to the fit of the whole model (CFI, RMSEA, etc.)
# I tried to do the posterior predictive checks in a similar way to what was presented in the course.
# That is, to compare the distribution of the variables from the data and from the draws generated from the posteriors.
# This code is based on the discussion in the blavaan google group https://groups.google.com/g/blavaan/c/BUIgpeynXSc/m/LxTxgLjTBgAJ
# Check the posterior predicted distributions of the observed variables
psamps  <- do.call("rbind", blavInspect(fit2, 'mcmc'))
lvsamps <- do.call("rbind", blavInspect(fit2, 'lvs'))
# Check the distribution of the observed variables based on the posteriors
posterior_pred_check <- lapply(seq(nrow(psamps)), function(i){
lavmodel <- blavaan:::fill_params(psamps[i,], fit@Model, fit@ParTable)
eta <- blavaan:::fill_eta(lvsamps[i,], fit@Model, fit@ParTable,
fit@SampleStats, fit@Data)
lavaan:::computeYHAT(lavmodel, lavmodel@GLIST, fit@SampleStats, ETA = eta)
})
# Use 50 random posterior draws
rand_samp <- sample(1:nrow(psamps), 50)
# Plot the real data against the posterior draws for all variables
var_names <- colnames(SimData)
par(mfrow=c(2,3))
for(var in 1:20){
plot(density(SimData[,var]), col="red", lwd=4, ylim=c(0,.6), main= paste("Distributions for variable", var_names[var]))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,var]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
}
summary(fit2)
summary(fit2, cf = F)
summary(fit2, ci = F)
summary(fit2, ci = T)
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
tinytex::reinstall_tinytex()
tinytex::reinstall_tinytex()
tinytex:: install_tinytex()
7000*0.015
60*24
35703 -33982
load("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 3/R/24-11-06 Sim Results/Ignored/MM_ResultIgnRow1.Rdata")
load("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 3/R/24-11-06 Sim Results/Normal/MM_ResultRow1.Rdata")
colMeans(ResultsRow_MM)
colMeans(ResultsRow_MM.ign)
3707/4
926.75/5
185.35/40
40*5*4
3707/800
38*5*4
3707/760
14*8
14*40
14*40*4
40*4
3707/160
1272/4
source("~/GitHub/MMG-SEM/R/MMG-SEM.R", echo=TRUE)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
library(lavaan)
library(semTools)
# remotes::install_github("simsem/semTools/semTools")
# remotes::install_github("simsem/semTools/semTools")
# wd
setwd("~/GitHub/OrdinalSim")
# source necessary functions
source("DataGeneration.R")
# Define models for future simulations
model <- '
# factor loadings
F1 =~ x1 + x2 + x3 + x4 + x5
F2 =~ z1 + z2 + z3 + z4 + z5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F4 ~ F1 + F3
F3 ~ F1 + F2
'
S1 <- '
# factor loadings
F1 =~ x1 + x2 + x3 + x4 + x5
F2 =~ z1 + z2 + z3 + z4 + z5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
'
# S1 <- list('F1 =~ x1 + x2 + x3 + x4 + x5',
#            'F2 =~ z1 + z2 + z3 + z4 + z5',
#            'F3 =~ m1 + m2 + m3 + m4 + m5',
#            'F4 =~ y1 + y2 + y3 + y4 + y5')
S2 <- '
# Regression parameters
F4 ~ F1 + F3
F3 ~ F1 + F2
'
# Generate dummy data
set.seed(1)
Data <- DataGeneration(model = model, nclus = 2, ngroups = 24, N_g = 200, reg_coeff = 0.4,
balance = "bal", NonInvSize = 0, NonInvItems = 2, NonInvG = 0.5,
NonInvThreshSize = 0, NonInvGThresh = 0.5,
NonInvType = "random", c = 4)
# With modelsel code (for continouos trials)
fit.con <- MMGSEM(dat = Data$SimData, S1 = S1, S2 = S2, group = "group", nclus = 2, seed = 1,
nstarts = 20, ordered = F, group.equal = "loadings")
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
mmgsem::summary_MMGSEM(fit.con)
mmgsem::se(fit.con)
se(fit.con)
unconstrained
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
se(fit.con)
se(fit.con)
cons_vec
unconstrained
lambda_vec
lambda_nam
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
se(fit.con)
lambda_vec
cons_vec
unconstrained
length(unconstrained == 0)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
se(fit.con)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
se(fit.con)
lambda_vec
# Generate dummy data
set.seed(1)
Data <- DataGeneration(model = model, nclus = 2, ngroups = 6, N_g = 200, reg_coeff = 0.4,
balance = "bal", NonInvSize = 0, NonInvItems = 2, NonInvG = 0.5,
NonInvThreshSize = 0, NonInvGThresh = 0.5,
NonInvType = "random", c = 4)
se(fit.con)
se(fit.con)
fit.con <- MMGSEM(dat = Data$SimData, S1 = S1, S2 = S2, group = "group", nclus = 2, seed = 1,
nstarts = 20, ordered = F, group.equal = "loadings")
se(fit.con)
idx.unco
source("~/GitHub/MMG-SEM/R/MMG-SEM.R", echo=TRUE)
fit.con <- MMGSEM(dat = Data$SimData, S1 = S1, S2 = S2, group = "group", nclus = 2, seed = 1,
nstarts = 20, ordered = F, group.equal = "loadings")
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
se(fit.con)
source("~/GitHub/MMG-SEM/R/MMG-SEM.R", echo=TRUE)
fit.con <- MMGSEM(dat = Data$SimData, S1 = S1, S2 = S2, group = "group", nclus = 2, seed = 1,
nstarts = 20, ordered = F, group.equal = "loadings")
se(fit.con)
